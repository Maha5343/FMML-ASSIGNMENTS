{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maha5343/FMML-ASSIGNMENTS/blob/main/Module_9_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 9: Convolutional Neural Networks\n",
        "## **Lab 4**\n",
        "### Module coordinator: Kushagra Agarwal"
      ],
      "metadata": {
        "id": "LnoibEy1XHa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/max/1200/1*QoqNAg2t6lF8Q6WWA6AbOg.png\" width=650px/>"
      ],
      "metadata": {
        "id": "WDybIRghMTSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using learnt representations\n",
        "In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\n",
        "\n",
        "\n",
        "We'll train a model to classify ants and bees. We have about 120 training images each for ants and bees. There are 75 validation images for each class. Usually, this is a very small dataset to generalize upon, if trained from scratch. Since we are using transfer learning, we should be able to generalize reasonably well.\n",
        "\n",
        "This dataset is a very small subset of imagenet.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rBs3aQm7XNJg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Tk-dMRFeSju9"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration (whether to run on GPU or CPU)\n",
        "device = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "K1yaW_B0XllE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract dataset\n",
        "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip -q hymenoptera_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkOxG4uIXtNw",
        "outputId": "66c332ee-4b77-429a-ac40-fa69a4da0bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-13 12:24:19--  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.249.85.22, 13.249.85.7, 13.249.85.10, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.249.85.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47286322 (45M) [application/zip]\n",
            "Saving to: ‘hymenoptera_data.zip.1’\n",
            "\n",
            "hymenoptera_data.zi 100%[===================>]  45.10M  78.6MB/s    in 0.6s    \n",
            "\n",
            "2023-06-13 12:24:19 (78.6 MB/s) - ‘hymenoptera_data.zip.1’ saved [47286322/47286322]\n",
            "\n",
            "replace hymenoptera_data/train/ants/0013035.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "val_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "data_dir = './hymenoptera_data'\n",
        "train_dataset = ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
        "val_dataset = ImageFolder(os.path.join(data_dir, 'val'), val_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4,shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4,shuffle=True, num_workers=2)\n",
        "class_names = train_dataset.classes\n"
      ],
      "metadata": {
        "id": "znqM97omX7ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_dataloader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "metadata": {
        "id": "afuX-c12YPZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, criterion, optimizer, num_epochs=25):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(True):\n",
        "              outputs = model(inputs)\n",
        "              _, preds = torch.max(outputs, 1)\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              # backward + optimize only if in training phase\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
        "\n",
        "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        print()"
      ],
      "metadata": {
        "id": "3EGEixYPYkLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=10):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "Sb395Sv3ZXW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "ZPJJWQjMYxeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "train_model(model_ft, train_dataloader, loss_func, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "ugJM2mEJY7ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft)"
      ],
      "metadata": {
        "id": "_yp2-TuFZBA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of How Pretrained models are used for Target Tasks"
      ],
      "metadata": {
        "id": "xq-YwkvuN_he"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/340225334/figure/fig2/AS:960014822944773@1605896778155/Mechanism-of-transfer-learning-using-pre-trained-models.png\" width=950px/>"
      ],
      "metadata": {
        "id": "xgGSEmX0N2zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions:\n",
        "1) What is the significance of using data augmentations like resize, crop etc on training data?\n",
        "\n",
        "2) What performance do you get if you don't use pretrained resnet model (Hint: Change pretrained=False and train the model)\n",
        "\n",
        "3) If the resnet model was pre-trained on dataset significantly different than the ants vs bees data, would you still get good performance by using this pretrained model?\n"
      ],
      "metadata": {
        "id": "QfsD509TaRI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer-1\n",
        "\n",
        "It increases the number of examples in the training set and also in the validation set while also introducing more variety in what the model sees and learns from."
      ],
      "metadata": {
        "id": "zjhtl_4fskSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer-2\n"
      ],
      "metadata": {
        "id": "QZEbICOjtT_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "model_ft = models.resnet18(pretrained=False)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "C5YizYP1tttq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "train_model(model_ft, train_dataloader, loss_func, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "9fxeCypft7OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft)"
      ],
      "metadata": {
        "id": "gptiOXx6qmdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy was less because the model has been already trained on large data."
      ],
      "metadata": {
        "id": "-nMmwnq6u5UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer-3\n",
        "\n",
        "The performance on the ants vs bees dataset may be affected if the pre-training dataset is significantly different.  If the pre-training dataset is significantly different from the ants vs bees data, the performance of the pre-trained model may not be as good as expected."
      ],
      "metadata": {
        "id": "qNcFnEOSvaYd"
      }
    }
  ]
}